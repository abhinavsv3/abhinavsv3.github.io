# Blog Evaluation: Scaling Thoughts

**Date:** February 20, 2026
**Evaluator:** Claude (prompted for honest assessment)
**Overall Rating:** 6/10 — Competent but undifferentiated

---

## Summary

The blog contains 7 posts on ML infrastructure topics (attention mechanisms, MoE, normalization, Flash Attention, linear attention, GPU utilization, inference phases). The writing is clear and technically accurate, but the content lacks originality, depth, and personal voice. These read like well-written study notes, not practitioner insights.

---

## Strengths

| Strength | Evidence |
|----------|----------|
| Clear writing | Well-structured, easy to follow |
| Technically accurate | Concepts are correct, properly explained |
| Good formatting | Tables, code blocks, headers used effectively |
| Executive summary first | Each post leads with the key takeaway |
| Practical structure | "When to use what" sections provide guidance |
| Honest | No fabricated data or fake "we measured" claims |

---

## Weaknesses

| Weakness | Impact |
|----------|--------|
| No original insights | Reader thinks: "I could find this in the paper/docs" |
| Surface-level depth | Experienced ML engineers won't learn anything new |
| No real data | Educational content without supporting evidence |
| Formulaic feel | All 7 posts have identical structure and tone |
| No personality | Could be written by anyone (or any LLM) |
| Heavy overlap | KV cache explained in 4 different posts |
| No code to run | No notebooks, no reproducible experiments |

---

## Post-by-Post Assessment

| Post | Rating | Verdict |
|------|--------|---------|
| MHA vs GQA vs MLA | 6/10 | Solid explainer, but summarizes existing sources |
| MoE Scaling | 6/10 | Good overview, nothing beyond DeepSeek's paper |
| Pre-Norm vs Post-Norm | 7/10 | Better—"why Post-Norm is back" narrative is useful |
| Flash Attention | 6/10 | Explains concept, but Tri Dao's blog does it better |
| Linear Attention | 6/10 | Covers tradeoffs without depth on any variant |
| GPU Utilization | 5/10 | Most generic—advice without evidence |
| Prefill vs Decode | 6/10 | Clear but standard knowledge |

---

## Comparison to Successful ML Blogs

### What they do that we don't:

**Lilian Weng (OpenAI)**
- Exhaustive surveys synthesizing 50+ papers
- Posts become canonical references
- Months of research per post

**Jay Alammar**
- Visual explanations that genuinely aid understanding
- The illustrations ARE the value
- Unique format no one else does

**Chip Huyen**
- Real production war stories
- Specific numbers from real systems
- "We tried X, it failed, here's what worked"

**Simon Willison**
- Shows his work—actual experiments, actual code
- Publishes thinking process, not just conclusions
- High volume, genuine curiosity

### Our gap:
We have none of these qualities. The posts are accurate but forgettable.

---

## What Would Make These Better

### 1. Depth over breadth
Instead of 7 surface posts, write ONE deep dive. Example: "I benchmarked every KV cache optimization on Llama 7B using my M2 Mac—here's what actually matters."

### 2. Add a thesis
"Here's how X works" is less interesting than "Everyone thinks X, but actually Y." Take a position.

### 3. Show your work
Run actual experiments. Profile real models. Share real numbers. Even small experiments on a Mac are more valuable than theoretical explanations.

### 4. Add personality
What surprised you? What's your hot take? What do you disagree with? Let the reader know a human wrote this.

### 5. Reduce redundancy
KV cache is explained in 4 posts. Write one definitive explanation, link to it from others.

### 6. Add runnable code
Notebooks, scripts, reproducible experiments. Let readers verify claims themselves.

---

## The Hard Questions

1. **Would someone bookmark this?** Probably not—same info exists elsewhere.
2. **Would someone share this with a colleague?** Unlikely—nothing novel to share.
3. **Would this get upvoted on HackerNews?** No—lacks original insight or data.
4. **Does this establish expertise?** No—demonstrates knowledge, not experience.
5. **Is this better than ChatGPT output?** Marginally—but not distinctively human.

---

## Recommended Path Forward

### Option A: The Deep Dive
- Pick ONE topic you genuinely care about
- Spend 2-4 weeks going deep
- Run real experiments (even on laptop)
- Write the definitive resource on that narrow topic
- One great post > seven mediocre posts

### Option B: The Experience Journal
- Wait until you have real production stories
- Document actual problems you solved at work
- Share real numbers (anonymized if needed)
- "War stories" are inherently differentiated

### Option C: The Toolmaker
- Build something useful (benchmark suite, visualization, tool)
- Write about what you learned building it
- The artifact itself is the differentiation

### Option D: Accept the Purpose
- These posts ARE useful for learning/SEO/portfolio
- Don't pretend they're HN-worthy thought leadership
- Use them as foundations for deeper work later

---

## Conclusion

The blog is technically competent but strategically unclear. It's not bad—it's just not good enough to stand out. The writing demonstrates understanding of ML infrastructure concepts, but doesn't demonstrate unique insight, real experience, or original thinking.

**The core issue:** These posts answer "what" and "how" but not "why should I read YOUR explanation instead of the original paper, the official docs, or any of 100 other summaries?"

Until that question has a good answer, the blog will remain competent but forgettable.

---

*This evaluation was requested by the blog author to get honest feedback. It should be revisited after implementing changes to measure improvement.*
